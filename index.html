<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Math - Visual Examples</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Bangers&family=Comic+Neue:wght@400;700&family=Fredoka:wght@400;600;700&family=Nunito:wght@400;600;700&family=Playfair+Display:wght@500;700&family=Source+Sans+3:wght@400;600;700&display=swap" rel="stylesheet">
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['\\(', '\\)'], ['$', '$']],
                displayMath: [['\\[', '\\]'], ['$$', '$$']]
            },
            svg: { fontCache: 'global' }
        };
    </script>
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body data-theme="light">
    <header>
        <h1>üß† Machine Learning Math Adventure</h1>
        <p>Playful visuals and mini missions to explore the math behind neural networks</p>
        <div class="mode-switcher" role="group" aria-label="Theme mode">
            <span class="mode-label">Mode:</span>
            <button class="mode-btn is-active" data-theme="light" type="button">Light</button>
            <button class="mode-btn" data-theme="dark" type="button">Dark</button>
            <button class="mode-btn" data-theme="kid" type="button">Kid Comic</button>
            <button class="mode-btn" data-theme="holiday" type="button">Holiday Kids</button>
            <button class="mode-btn" data-theme="adult" type="button">Adult</button>
        </div>
    </header>

    <nav>
        <a href="#fundamentals">Foundations</a>
        <a href="#vectors">Vectors</a>
        <a href="#matrices">Matrices</a>
        <a href="#gradient-descent">Gradient Descent</a>
        <a href="#activations">Activation Functions</a>
        <a href="#neural-network">Neural Network</a>
        <a href="#backprop">Backpropagation</a>
    </nav>

    <div class="holiday-parade" aria-hidden="true">
        <div class="holiday-character santa" aria-hidden="true">
            <span class="holiday-emoji" aria-hidden="true">üéÖ</span>
            <span class="holiday-label">Santa</span>
        </div>
        <div class="holiday-character spidey" aria-hidden="true">
            <img class="holiday-image" src="assets/spiderman-mask.svg" alt="Spiderman mask">
            <span class="holiday-label">Spidey</span>
        </div>
    </div>

    <main>
        <!-- Foundations Section -->
        <section id="fundamentals" class="example-section fundamentals-section">
            <h2>1. Foundations: Your Self-Guided Math Path</h2>
            <p class="section-intro">Start here! Each step unlocks a superpower for understanding neural networks. Tap a tab to switch the graphic and see the idea in action.</p>
            <div class="learning-path">
                <div class="path-card">
                    <span class="path-step">Step 1</span>
                    <h4>Linear Algebra: Space Benders</h4>
                    <p>Learn how vectors and matrices stretch, rotate, and move space.</p>
                    <span class="path-goal">Goal: read \( \mathbf{h} = W\mathbf{x} + \mathbf{b} \).</span>
                </div>
                <div class="path-card">
                    <span class="path-step">Step 2</span>
                    <h4>Calculus: Change Detective</h4>
                    <p>Understand slopes, tiny nudges, and the chain rule.</p>
                    <span class="path-goal">Goal: follow gradients through a network.</span>
                </div>
                <div class="path-card">
                    <span class="path-step">Step 3</span>
                    <h4>Optimization: Mountain Hikes</h4>
                    <p>Use gradients to walk downhill and find the best answers.</p>
                    <span class="path-goal">Goal: tune the learning rate \( \eta \).</span>
                </div>
                <div class="path-card">
                    <span class="path-step">Step 4</span>
                    <h4>Probability: Confidence Radar</h4>
                    <p>Turn scores into probabilities and measure mistakes.</p>
                    <span class="path-goal">Goal: use softmax and cross-entropy.</span>
                </div>
                <div class="path-card">
                    <span class="path-step">Step 5</span>
                    <h4>Matrix Calculus: Fast Backprop</h4>
                    <p>Compute gradients for whole batches at once.</p>
                    <span class="path-goal">Goal: track shapes and vectorized rules.</span>
                </div>
            </div>
            <div class="content-grid fundamentals-grid">
                <div class="explanation">
                    <p class="foundation-lead">Neural networks are a stack of math ideas. Each tab below zooms in on one layer of that stack.</p>
                    <div class="concept-tabs" role="tablist">
                        <button class="concept-tab is-active" data-topic="linear" role="tab" aria-controls="concept-linear" aria-selected="true">Linear Algebra</button>
                        <button class="concept-tab" data-topic="calculus" role="tab" aria-controls="concept-calculus" aria-selected="false">Calculus</button>
                        <button class="concept-tab" data-topic="optimization" role="tab" aria-controls="concept-optimization" aria-selected="false">Optimization</button>
                        <button class="concept-tab" data-topic="probability" role="tab" aria-controls="concept-probability" aria-selected="false">Probability</button>
                        <button class="concept-tab" data-topic="matrix" role="tab" aria-controls="concept-matrix" aria-selected="false">Matrix Calc</button>
                    </div>
                    <div class="concept-panels">
                        <div class="concept-panel is-active" id="concept-linear" data-topic="linear" role="tabpanel">
                            <h3>Linear algebra: what the network is</h3>
                            <p>Think of a matrix as a magic machine that bends space. Each layer takes a vector and transforms it.</p>
                            <div class="math-formula">
                                \[
                                \mathbf{h} = W\mathbf{x} + \mathbf{b}
                                \]
                                \[
                                \mathbf{a} = \mathrm{ReLU}(\mathbf{h})
                                \]
                            </div>
                            <p>In 3Blue1Brown style, imagine a grid of points being stretched and tilted. That is what \(W\) does.</p>
                            <ul class="concept-bullets">
                                <li>Vectors are arrows (direction + length).</li>
                                <li>Matrices are transformations (stretch, rotate, shear).</li>
                                <li>Layers stack these transformations with a nonlinearity.</li>
                            </ul>
                            <div class="mini-mission">Mini mission: pick a vector and predict where the grid sends it.</div>
                        </div>
                        <div class="concept-panel" id="concept-calculus" data-topic="calculus" role="tabpanel">
                            <h3>Calculus: how learning works</h3>
                            <p>Derivatives tell us how fast things change. If the loss is a hill, the derivative tells the slope.</p>
                            <div class="math-formula">
                                \[
                                \frac{d}{dx}f(g(x)) = f'(g(x)) \cdot g'(x)
                                \]
                            </div>
                            <p>Backprop is the chain rule applied again and again through the whole network.</p>
                            <ul class="concept-bullets">
                                <li>Local slope \(\times\) upstream slope = new slope.</li>
                                <li>Think of it as water flowing through pipes.</li>
                            </ul>
                            <div class="mini-mission">Mini mission: point to where the slope is steepest.</div>
                        </div>
                        <div class="concept-panel" id="concept-optimization" data-topic="optimization" role="tabpanel">
                            <h3>Optimization: gradient descent and learning rate</h3>
                            <p>Once we know the slope, we take a step downhill to reduce the loss.</p>
                            <div class="math-formula">
                                \[
                                \theta \leftarrow \theta - \eta \nabla_\theta L
                                \]
                            </div>
                            <ul>
                                <li><strong>\(\eta\)</strong>: learning rate (step size)</li>
                                <li>Too big &rarr; unstable or diverges</li>
                                <li>Too small &rarr; slow progress</li>
                            </ul>
                            <div class="mini-mission">Mini mission: choose a step size that reaches the valley without bouncing.</div>
                        </div>
                        <div class="concept-panel" id="concept-probability" data-topic="probability" role="tabpanel">
                            <h3>Probability + information theory</h3>
                            <p>For classification, the network turns scores into probabilities and compares them to the truth.</p>
                            <div class="math-formula">
                                \[
                                \mathbf{z} = W\mathbf{x} + \mathbf{b}
                                \]
                                \[
                                \hat{y}_i = \frac{e^{z_i}}{\sum_k e^{z_k}}
                                \]
                                \[
                                L = -\sum_i y_i \log \hat{y}_i
                                \]
                            </div>
                            <p>Key result (used constantly): \( \nabla_{\mathbf{z}} L = \hat{\mathbf{y}} - \mathbf{y} \).</p>
                            <div class="mini-mission">Mini mission: spot the biggest probability bar.</div>
                        </div>
                        <div class="concept-panel" id="concept-matrix" data-topic="matrix" role="tabpanel">
                            <h3>Matrix calculus: the speed path</h3>
                            <p>To train fast, we compute gradients for a whole batch at once.</p>
                            <div class="math-formula">
                                \[
                                Y = XW
                                \]
                                \[
                                \frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} W^T
                                \]
                                \[
                                \frac{\partial L}{\partial W} = X^T \frac{\partial L}{\partial Y}
                                \]
                            </div>
                            <p>Shapes are your superpower: match the dimensions and the math works out.</p>
                            <div class="mini-mission">Mini mission: label the shapes of \(X\), \(W\), and \(Y\).</div>
                        </div>
                    </div>
                </div>
                <div class="visualization">
                    <canvas id="fundamentalsCanvas" width="420" height="360"></canvas>
                    <div class="controls fundamentals-controls">
                        <button onclick="cycleFundamentals()">Next concept</button>
                        <p class="helper-text">Tap a tab to switch the picture.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Vectors Section -->
        <section id="vectors" class="example-section">
            <h2>2. Vectors & Vector Playground</h2>
            <p class="section-intro">Explore vectors as data points, similarity scores, and distances. Switch to Deep Dive when you want the advanced geometry.</p>
            <div class="vector-mode-switcher" role="group" aria-label="Vector depth mode">
                <button class="toggle-btn is-active" type="button" data-vector-mode="basic">Basic playground</button>
                <button class="toggle-btn" type="button" data-vector-mode="deep">Deep dive</button>
            </div>
            <div class="vector-mode-panel is-active" data-vector-mode="basic">
                <div class="content-grid">
                    <div class="explanation">
                        <h3>Vector playground</h3>
                        <p>Think of vector A as a data point \(x\) and vector B as model weights \(w\). Use the buttons to see how scores and distances behave.</p>
                        <ul class="concept-bullets">
                            <li>Data point: the arrow from the origin to \(x\).</li>
                            <li>Dot product: the shadow of \(x\) on \(w\).</li>
                            <li>Cosine: angle-only similarity.</li>
                            <li>Distance: how far two points are apart.</li>
                        </ul>
                        <div class="math-formula" id="vectorOperationFormula">\[
                        x = [x_1, x_2], \quad w = [w_1, w_2]
                        \]</div>
                        <div class="vector-metrics">
                            <div class="metric" data-vector-metric="sum">
                                <span class="metric-label">x + w</span>
                                <span class="metric-value" id="vectorSum">[0, 0]</span>
                            </div>
                            <div class="metric" data-vector-metric="dot">
                                <span class="metric-label">Dot</span>
                                <span class="metric-value" id="vectorDot">0</span>
                            </div>
                            <div class="metric" data-vector-metric="cosine">
                                <span class="metric-label">Cosine</span>
                                <span class="metric-value" id="vectorCosine">0</span>
                            </div>
                            <div class="metric" data-vector-metric="angle">
                                <span class="metric-label">Angle</span>
                                <span class="metric-value" id="vectorAngle">0¬∞</span>
                            </div>
                            <div class="metric" data-vector-metric="distance">
                                <span class="metric-label">Distance</span>
                                <span class="metric-value" id="vectorDistance">0</span>
                            </div>
                        </div>
                    </div>
                    <div class="visualization">
                        <canvas id="vectorCanvas" width="400" height="400"></canvas>
                        <div class="controls vector-controls">
                            <div class="toggle-group" role="group" aria-label="Vector operation">
                                <button class="toggle-btn is-active" type="button" data-vector-op="data">Data point</button>
                                <button class="toggle-btn" type="button" data-vector-op="addition">Addition</button>
                                <button class="toggle-btn" type="button" data-vector-op="dot">Dot product</button>
                                <button class="toggle-btn" type="button" data-vector-op="cosine">Cosine</button>
                                <button class="toggle-btn" type="button" data-vector-op="distance">Distance</button>
                            </div>
                            <div class="slider-group">
                                <span class="slider-title">Vector A (x)</span>
                                <label>A.x <span id="vecAxVal">2.0</span></label>
                                <input type="range" id="vecAx" min="-4" max="4" step="0.1" value="2">
                                <label>A.y <span id="vecAyVal">3.0</span></label>
                                <input type="range" id="vecAy" min="-4" max="4" step="0.1" value="3">
                            </div>
                            <div class="slider-group">
                                <span class="slider-title">Vector B (w)</span>
                                <label>B.x <span id="vecBxVal">1.0</span></label>
                                <input type="range" id="vecBx" min="-4" max="4" step="0.1" value="1">
                                <label>B.y <span id="vecByVal">4.0</span></label>
                                <input type="range" id="vecBy" min="-4" max="4" step="0.1" value="4">
                            </div>
                            <div class="slider-group">
                                <span class="slider-title">Zoom</span>
                                <label>Zoom <span id="vecScaleVal">1.0</span></label>
                                <input type="range" id="vecScale" min="0.5" max="2" step="0.1" value="1">
                            </div>
                            <button type="button" id="vectorAnimateButton" onclick="animateVectorAddition()">Animate Addition</button>
                        </div>
                    </div>
                </div>
            </div>
            <div class="vector-mode-panel" data-vector-mode="deep">
                <div class="content-grid vector-scenes">
                    <div class="explanation">
                        <h3>Deep dive: advanced geometry</h3>
                        <p>Step through projections, gradients, regularization, and attention with visual intuition.</p>
                        <div class="scene-panel" id="vectorScenePanel" aria-live="polite">
                            <div class="scene-header">
                                <span class="scene-badge" id="vectorSceneBadge">Scene 1 of 4</span>
                                <h4 id="vectorSceneTitle">Scene 1: Projection as a shadow</h4>
                            </div>
                            <div class="scene-block">
                                <h5>Visual</h5>
                                <p id="vectorSceneVisual"></p>
                            </div>
                            <div class="scene-block">
                                <h5>Mini example</h5>
                                <p id="vectorSceneExample"></p>
                            </div>
                            <div class="scene-block">
                                <h5>ML intuition</h5>
                                <p id="vectorSceneIntuition"></p>
                            </div>
                            <div class="math-formula" id="vectorSceneMath"></div>
                        </div>
                    </div>
                    <div class="visualization">
                        <canvas id="vectorSceneCanvas" width="420" height="360"></canvas>
                        <div class="controls scene-controls">
                            <button type="button" id="vectorPrevScene">Previous scene</button>
                            <button type="button" id="vectorNextScene">Next scene</button>
                        </div>
                    </div>
                </div>
                <div class="vector-toolkit">
                    <h3>Deep dive concepts</h3>
                    <p class="section-intro">Advanced vector ideas that show up in PCA, optimization, and attention.</p>
                    <div class="vector-grid">
                        <article class="vector-card">
                            <span class="path-step">1</span>
                            <h4>Projections & orthogonality</h4>
                            <ul>
                                <li>Projection onto \(u\): \( \mathrm{proj}_u(x) = \frac{x \cdot u}{u \cdot u} u \).</li>
                                <li>Orthogonal vectors give clean coordinate systems (PCA/SVD).</li>
                            </ul>
                        </article>
                        <article class="vector-card">
                            <span class="path-step">2</span>
                            <h4>Subspaces, basis, rank</h4>
                            <ul>
                                <li>Span is the set of all linear combinations of vectors.</li>
                                <li>Rank is the dimension of that span (effective dimensionality).</li>
                            </ul>
                        </article>
                        <article class="vector-card">
                            <span class="path-step">3</span>
                            <h4>Gradients, Jacobians, Hessians</h4>
                            <ul>
                                <li>\(\nabla_\theta L\) points steepest uphill.</li>
                                <li>Jacobians handle vector outputs; Hessians capture curvature.</li>
                            </ul>
                        </article>
                        <article class="vector-card">
                            <span class="path-step">4</span>
                            <h4>Vector statistics</h4>
                            <ul>
                                <li>Mean vector and covariance describe feature distributions.</li>
                                <li>Centering and whitening stabilize training and PCA.</li>
                            </ul>
                        </article>
                        <article class="vector-card">
                            <span class="path-step">5</span>
                            <h4>Regularization geometry</h4>
                            <ul>
                                <li>L2 prefers small norms; L1 encourages sparsity.</li>
                                <li>Constraint shapes explain why L1 yields zeros.</li>
                            </ul>
                        </article>
                        <article class="vector-card">
                            <span class="path-step">6</span>
                            <h4>Attention via dot products</h4>
                            <ul>
                                <li>Similarity scores become weights after softmax.</li>
                                <li>Output is a weighted sum of value vectors.</li>
                            </ul>
                        </article>
                    </div>
                </div>
            </div>
        </section>

        <!-- Matrices Section -->
        <section id="matrices" class="example-section">
            <h2>3. Matrices: Addition & Multiplication</h2>
            <div class="content-grid">
                <div class="explanation">
                    <h3>Matrix playground</h3>
                    <p>Switch between addition and multiplication to see how matrices combine and transform data.</p>
                    <div class="math-formula" id="matrixOperationFormula">\[
                    C = AB
                    \]</div>
                    <p id="matrixOperationNote">Multiplication mixes rows and columns to transform vectors.</p>
                </div>
                <div class="visualization">
                    <canvas id="matrixCanvas" width="420" height="320"></canvas>
                    <div class="controls matrix-controls">
                        <div class="toggle-group" role="group" aria-label="Matrix operation">
                            <button class="toggle-btn is-active" type="button" data-matrix-op="multiply">Multiplication</button>
                            <button class="toggle-btn" type="button" data-matrix-op="add">Addition</button>
                        </div>
                        <button type="button" id="matrixAnimateButton" onclick="animateMatrixOperation()">Animate</button>
                    </div>
                </div>
            </div>
        </section>

        <!-- Gradient Descent Section -->
        <section id="gradient-descent" class="example-section">
            <h2>4. Gradient Descent</h2>
            <div class="content-grid">
                <div class="explanation">
                    <h3>Finding the Minimum</h3>
                    <p>Gradient descent is how neural networks learn. It's like walking downhill to find the lowest point:</p>
                    <div class="math-formula">
                        \[
                        \theta_{\text{new}} = \theta_{\text{old}} - \alpha \nabla J(\theta)
                        \]
                    </div>
                    <ul>
                        <li><strong>\(\theta\)</strong>: Parameter being optimized</li>
                        <li><strong>\(\alpha\)</strong>: Learning rate (step size)</li>
                        <li><strong>\(\nabla J(\theta)\)</strong>: Gradient (direction of steepest increase)</li>
                    </ul>
                </div>
                <div class="visualization">
                    <canvas id="gradientCanvas" width="400" height="400"></canvas>
                    <div class="controls">
                        <label>Learning Rate: <input type="range" id="learningRate" min="0.01" max="0.5" step="0.01" value="0.1"></label>
                        <button onclick="runGradientDescent()">Run Gradient Descent</button>
                        <button onclick="resetGradientDescent()">Reset</button>
                    </div>
                </div>
            </div>
        </section>

        <!-- Activation Functions Section -->
        <section id="activations" class="example-section">
            <h2>5. Activation Functions</h2>
            <div class="content-grid">
                <div class="explanation">
                    <h3>Non-Linear Transformations</h3>
                    <p>Activation functions add non-linearity to neural networks, enabling them to learn complex patterns:</p>
                    
                    <h4>Sigmoid: \( \sigma(x) = \frac{1}{1+e^{-x}} \)</h4>
                    <p>Squashes values to (0, 1). Used for binary classification.</p>
                    
                    <h4>ReLU: \( f(x) = \max(0, x) \)</h4>
                    <p>Most popular! Simple and effective. Returns x if positive, 0 otherwise.</p>
                    
                    <h4>Tanh: \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)</h4>
                    <p>Squashes values to (-1, 1). Zero-centered version of sigmoid.</p>
                </div>
                <div class="visualization">
                    <canvas id="activationCanvas" width="400" height="400"></canvas>
                    <div class="controls">
                        <label>
                            <input type="checkbox" id="showSigmoid" checked> Sigmoid
                        </label>
                        <label>
                            <input type="checkbox" id="showReLU" checked> ReLU
                        </label>
                        <label>
                            <input type="checkbox" id="showTanh" checked> Tanh
                        </label>
                    </div>
                </div>
            </div>
        </section>

        <!-- Neural Network Section -->
        <section id="neural-network" class="example-section">
            <h2>6. Neural Network Forward Propagation</h2>
            <div class="content-grid">
                <div class="explanation">
                    <h3>How Data Flows Through a Network</h3>
                    <p>Forward propagation is the process of computing predictions:</p>
                    <ol>
                        <li><strong>Input Layer</strong>: Receives the data</li>
                        <li><strong>Hidden Layers</strong>: Apply transformations (weights + activation)</li>
                        <li><strong>Output Layer</strong>: Produces predictions</li>
                    </ol>
                    <div class="math-formula">
                        \[
                        \text{hidden} = \text{activation}(\text{input} \times W_1 + b_1)
                        \]
                        \[
                        \text{output} = \text{activation}(\text{hidden} \times W_2 + b_2)
                        \]
                    </div>
                    <p>Click neurons to see the computation flow!</p>
                </div>
                <div class="visualization">
                    <canvas id="neuralNetCanvas" width="400" height="400"></canvas>
                    <div class="controls">
                        <button onclick="runForwardProp()">Run Forward Propagation</button>
                        <button onclick="resetNetwork()">Reset</button>
                    </div>
                </div>
            </div>
        </section>

        <!-- Backpropagation Section -->
        <section id="backprop" class="example-section">
            <h2>7. Backpropagation</h2>
            <div class="content-grid">
                <div class="explanation">
                    <h3>How Neural Networks Learn</h3>
                    <p>Backpropagation calculates how to adjust weights to reduce error:</p>
                    <ol>
                        <li><strong>Forward Pass</strong>: Compute predictions</li>
                        <li><strong>Calculate Error</strong>: Compare prediction to truth</li>
                        <li><strong>Backward Pass</strong>: Propagate error backwards</li>
                        <li><strong>Update Weights</strong>: Adjust using gradients</li>
                    </ol>
                    <div class="math-formula">
                        \[
                        \frac{\partial \text{Loss}}{\partial w} = \frac{\partial \text{Loss}}{\partial \text{output}} \cdot \frac{\partial \text{output}}{\partial w}
                        \]
                    </div>
                    <p>Uses chain rule to compute gradients efficiently!</p>
                    <figure class="wip-card">
                        <img src="assets/robot-wip.svg" alt="Friendly robot holding a WIP sign">
                        <figcaption>
                            <span class="wip-label">Work in progress</span>
                            We're building a step-by-step backprop playground next. Stay tuned!
                        </figcaption>
                    </figure>
                </div>
                <div class="visualization">
                    <canvas id="backpropCanvas" width="400" height="400"></canvas>
                    <div class="controls">
                        <button onclick="runBackprop()">Run Backpropagation</button>
                        <button onclick="resetBackprop()">Reset</button>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>Built with ‚ù§Ô∏è for intuitive machine learning education</p>
        <p>All visualizations are interactive - click buttons to see animations!</p>
    </footer>

    <script src="script.js"></script>
</body>
</html>
